/**
 * OpenRouter AI Client (supports 50+ models)
 */

import OpenAI from "openai";
import { buildPrompt } from "./prompts";

// Initialize OpenRouter client
const openrouter = new OpenAI({
  baseURL: "https://openrouter.ai/api/v1",
  apiKey: process.env.EXPO_PUBLIC_OPENROUTER_API_KEY || "",
  defaultHeaders: {
    "HTTP-Referer": "https://mln111.app",
    "X-Title": "MLN111 Learning App",
  },
});

/**
 * Generate AI response using OpenRouter with multiple model fallback
 */
export async function generateResponse(
  context: string,
  question: string,
  lessons?: { slug: string; title: string }[]
): Promise<string> {
  // Check if API key exists
  if (!process.env.EXPO_PUBLIC_OPENROUTER_API_KEY) {
    console.error("‚ùå Missing EXPO_PUBLIC_OPENROUTER_API_KEY");
    return "Xin l·ªói, h·ªá th·ªëng AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng th√™m API key v√†o .env file.";
  }

  // Build system prompt with context and lessons
  const systemPrompt = buildPrompt(context, "", lessons);

  // Try multiple FREE models in order
  const modelsToTry = [
    "google/gemini-2.0-flash-exp:free", // Gemini 2.0 (free, fast)
    "meta-llama/llama-3.2-3b-instruct:free", // Llama 3.2 (free)
    "mistralai/mistral-7b-instruct:free", // Mistral 7B (free)
  ];

  for (let i = 0; i < modelsToTry.length; i++) {
    const modelName = modelsToTry[i];
    try {
      // Only log first attempt
      if (i === 0) {
        console.log(`ü§ñ Calling AI via OpenRouter...`);
      }

      const completion = await openrouter.chat.completions.create({
        model: modelName,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: question },
        ],
        temperature: 0.7,
        max_tokens: 800,
      });

      const text = completion.choices[0]?.message?.content || "";

      if (text) {
        console.log(`‚úÖ AI response received from ${modelName.split("/")[0]}`);

        // Append lesson links section if available
        let finalResponse = text;
        if (lessons && lessons.length > 0) {
          finalResponse += "\n\nüìö **B√†i h·ªçc li√™n quan:**\n";
          lessons.forEach((lesson) => {
            finalResponse += `‚Ä¢ [${lesson.title}](lesson://${lesson.slug})\n`;
          });
        }

        return finalResponse;
      }
    } catch (error: any) {
      // Only log if last model failed
      if (i === modelsToTry.length - 1) {
        console.error(`‚ùå All OpenRouter models failed:`, error.message);
      }

      // If this is the last model, return error message
      if (i === modelsToTry.length - 1) {
        // Handle specific errors
        if (
          error.message?.includes("API key") ||
          error.message?.includes("401")
        ) {
          return "Xin l·ªói, API key kh√¥ng h·ª£p l·ªá.\n\nüí° L·∫•y key mi·ªÖn ph√≠ t·∫°i: https://openrouter.ai/keys";
        }

        if (
          error.message?.includes("quota") ||
          error.message?.includes("429") ||
          error.message?.includes("rate limit")
        ) {
          return "‚è∞ ƒê√£ v∆∞·ª£t quota h√¥m nay.\n\nüí° Gi·∫£i ph√°p:\n- ƒê·ª£i v√†i ph√∫t r·ªìi th·ª≠ l·∫°i\n- Ho·∫∑c t·∫°o API key m·ªõi t·∫°i: https://openrouter.ai/keys\n- Free tier: 10-20 requests/day/model";
        }

        if (
          error.message?.includes("overloaded") ||
          error.message?.includes("503")
        ) {
          return "Xin l·ªói, server AI ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau v√†i gi√¢y. ‚è≥";
        }

        if (error.message?.includes("network")) {
          return "Xin l·ªói, kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server AI. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet. üì°";
        }

        return "Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i. üîÑ\n\nN·∫øu l·ªói ti·∫øp t·ª•c, vui l√≤ng ki·ªÉm tra API key t·∫°i: https://openrouter.ai/keys";
      }

      // Try next model after a short delay
      await new Promise((resolve) => setTimeout(resolve, 1000));
    }
  }

  return "Xin l·ªói, kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn AI. Vui l√≤ng th·ª≠ l·∫°i sau. üîÑ";
}

/**
 * Validate question before sending to AI
 */
export function validateQuestion(question: string): {
  valid: boolean;
  error?: string;
} {
  const trimmed = question.trim();

  if (trimmed.length === 0) {
    return { valid: false, error: "C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng" };
  }

  if (trimmed.length < 2) {
    return { valid: false, error: "C√¢u h·ªèi qu√° ng·∫Øn (t·ªëi thi·ªÉu 2 k√Ω t·ª±)" };
  }

  if (trimmed.length > 500) {
    return { valid: false, error: "C√¢u h·ªèi qu√° d√†i (t·ªëi ƒëa 500 k√Ω t·ª±)" };
  }

  return { valid: true };
}
